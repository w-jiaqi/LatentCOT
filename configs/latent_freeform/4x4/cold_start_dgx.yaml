dataset: 4x4
model: meta-llama/Llama-3.2-1B
tokenizer: meta-llama/Llama-3.2-1B
epochs: 5
checkpoints_dir: checkpoints/latent-cot-grpo
batch_num: 32
max_new_latents: 8
checkpoints_name: cold_start
save_steps: 10000
lr: 5e-6