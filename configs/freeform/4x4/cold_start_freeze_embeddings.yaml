dataset: 4x4
model: meta-llama/Llama-3.2-1B
tokenizer: meta-llama/Llama-3.2-1B
epochs: 5
checkpoints_dir: checkpoints
batch_num: 32
max_new_latents: 8
checkpoints_name: 4x4_cold_start_freeze_embeddings
save_steps: 10000
lr: 5.0e-6
freeze_embeddings: true
unembed_latents: true
dynamically_stop: false
answer_loss_scaling: 2.0