dataset: gsm8k
model: meta-llama/Llama-3.2-1B
tokenizer: meta-llama/Llama-3.2-1B
epochs: 25
checkpoints_dir: checkpoints
batch_num: 8
max_new_latents: 8
checkpoints_name: gsm8k_cold_start
save_steps: 10000
lr: 5.0e-6
freeze_embeddings: false
unembed_latents: true
dynamically_stop: 
answer_loss_scaling: 2.0