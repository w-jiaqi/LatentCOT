{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d313006",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gscratch/ark/anjo0/LatentCOT/env/lib64/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/gscratch/ark/anjo0/LatentCOT/env/lib64/python3.9/site-packages/transformers/utils/hub.py:106: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from sft.models.latent_tokenizer import LatentTokenizer\n",
    "from sft.models.latent_cot_model import LatentCOTModel\n",
    "\n",
    "from data.multiplication_dataset import get_4x4_dataset\n",
    "from data.gsm8k_dataset import get_gsm8k_dataset\n",
    "from data.dataset import get_latent_cot_grpo_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9de2da1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/Llama-3.2-1B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb029b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    }
   ],
   "source": [
    "tokenizer = LatentTokenizer(model_id)\n",
    "model = LatentCOTModel(model_id, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b07e6f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[128000, 9016, 7649], [128000, 1985, 1296]], 'attention_mask': [[1, 1, 1], [1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer([\"testing testing\", \"test test\"])\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6de07d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 808000/808000 [03:16<00:00, 4101.95 examples/s]\n",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 1834.70 examples/s]\n"
     ]
    }
   ],
   "source": [
    "base_ds = get_4x4_dataset(streaming=False)\n",
    "ds = get_latent_cot_grpo_dataset(base_ds, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad5f24c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(128260, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(model.model.get_input_embeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2553961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question_ids', 'question_attention_mask', 'reasoning_ids', 'reasoning_attention_mask', 'reasoning_labels', 'answer_ids', 'answer_attention_mask', 'answer_labels'],\n",
      "    num_rows: 7473\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(ds['train'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
